.. image:: https://travis-ci.org/willpatterson/LogoBatch.svg?branch=master
    :target: https://travis-ci.org/willpatterson/LogoBatch

.. image:: https://api.codacy.com/project/badge/Coverage/d2ae03a947f1499486897e6c6f53e36e    
    :target: https://www.codacy.com/app/wpatt2/LogoBatch?utm_source=github.com&amp;utm_medium=referral&amp;utm_content=willpatterson/LogoBatch&amp;utm_campaign=Badge_Coverage


*********
LogoBatch
*********

``LogoBatch`` is a simple ad-hoc grid system for distributing large computational batches across
clusters and single nodes, such as desktop computers, as if they were the same system.

What Makes LogoBatch Different?
===============================
LogoBatch is a ad-hoc grid system. This means that end-users can use LogoBatch to easily build computing
grids out of systems they do not have root access too.

LogoBatch does not need to be installed on a grid's compute nodes, all the nodes are
configured and then deconstructed by LogoBatch durring runtime, optionally leaving no trace on 
any system used to run jobs.

All inter-system jobs are distributed using SSH. LogoBatch will have interfaces for schedulers and
existing grid computing systems allowing seamless job deployment between different computing system types.

jobs across user-defined computing resources. 
**LogoBatch is pre-release software.**
LogoBatch is currently being refactored.

Batch Of Batches (BBatch)
-------------------------
As the name suggests, a BBatch is a set of batches defined in a YAML file
to be passed to LogoBatch, which distributes them over your defined 
computing resources.

Batch Image
-----------

Batch Images are packages to be used to save and distribute batches. Batch
Images can be created with using LogoBatch's utility ``makebimg``.

Batch Image structure
=====================

Some structural elements were taken from 
`cookie-cutter-data-science <https://github.com/drivendata/cookiecutter-data-science>`_.

::

    batch_image
    |
    +LICENSE
    +Makefile        #Generated by LogoBatch to run analysis
    +README.rst      #General Project and how-to-use info
    |
    +--docs          #Directory for housing documentation
    +--src           #Directory for storing code
    |
    +--batch_info
    |  |
    |  +bbatch_1.yml #There can be as many bbatches as necessary
    |  +bbatch_2.yml #
    |  +inputs.csv   #There can be as many input csv files as necessary
    |  +inputs2.csv  #
    |
    +--data
       |
       +--raw        #Raw data files
       +--external   #Data from external sources
       +--interim    #Intermediate Data
       +--processed  #Batch Output
          |
          +--bbatch_1
          |  |    
          |  +--batch_1
          |  |  |
          |  |  +--Job1
          |  |  |  |
          |  |  |  +outfile(s).whatever 
          |  |  |  +slurm.out
          |  |  |  +jobfile.sh
          |  |  |
          |  |  +--Job2 ...
          |  |  
          |  +--batch_2 ...  
          |
          +--bbatch_2 ...
 
